{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "pandas version: 0.23.4\n",
      "matplotlib version: 3.0.1\n",
      "NumPy version: 1.15.4\n",
      "SciPy version: 1.2.0\n",
      "IPython version: 7.0.1\n",
      "scikit-learn version: 0.20.2\n"
     ]
    }
   ],
   "source": [
    "import os as os\n",
    "\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__))\n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__))\n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Model Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizazion Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Display up to 60 columns of a dataframe\n",
    "pd.set_option('display.max_columns', 15)\n",
    "# use ggplt style for plotting\n",
    "mpl.style.use('ggplot')\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data from csv\n",
    "data = pd.read_csv(\"../data/Data_Import_Template_v1.0-1.csv\", sep=\";\")\n",
    "\n",
    "# create copy\n",
    "data_copy = data.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5960 entries, 0 to 5959\n",
      "Data columns (total 13 columns):\n",
      "BAD        5960 non-null int64\n",
      "LOAN       5960 non-null int64\n",
      "MORTDUE    5442 non-null float64\n",
      "VALUE      5848 non-null float64\n",
      "REASON     5708 non-null object\n",
      "JOB        5681 non-null object\n",
      "YOJ        5445 non-null float64\n",
      "DEROG      5252 non-null float64\n",
      "DELINQ     5380 non-null float64\n",
      "CLAGE      5652 non-null float64\n",
      "NINQ       5450 non-null float64\n",
      "CLNO       5738 non-null float64\n",
      "DEBTINC    4693 non-null float64\n",
      "dtypes: float64(9), int64(2), object(2)\n",
      "memory usage: 605.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>JOB</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5960.000000</td>\n",
       "      <td>5960.000000</td>\n",
       "      <td>5442.000000</td>\n",
       "      <td>5848.000000</td>\n",
       "      <td>5708</td>\n",
       "      <td>5681</td>\n",
       "      <td>5445.000000</td>\n",
       "      <td>5252.000000</td>\n",
       "      <td>5380.000000</td>\n",
       "      <td>5652.000000</td>\n",
       "      <td>5450.000000</td>\n",
       "      <td>5738.000000</td>\n",
       "      <td>4693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3928</td>\n",
       "      <td>2388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.199497</td>\n",
       "      <td>18607.969799</td>\n",
       "      <td>73760.817200</td>\n",
       "      <td>101776.048741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.922268</td>\n",
       "      <td>0.254570</td>\n",
       "      <td>0.449442</td>\n",
       "      <td>179.766275</td>\n",
       "      <td>1.186055</td>\n",
       "      <td>21.296096</td>\n",
       "      <td>33.779915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.399656</td>\n",
       "      <td>11207.480417</td>\n",
       "      <td>44457.609458</td>\n",
       "      <td>57385.775334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.573982</td>\n",
       "      <td>0.846047</td>\n",
       "      <td>1.127266</td>\n",
       "      <td>85.810092</td>\n",
       "      <td>1.728675</td>\n",
       "      <td>10.138933</td>\n",
       "      <td>8.601746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>2063.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11100.000000</td>\n",
       "      <td>46276.000000</td>\n",
       "      <td>66075.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.116702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>29.140031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16300.000000</td>\n",
       "      <td>65019.000000</td>\n",
       "      <td>89235.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>34.818262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23300.000000</td>\n",
       "      <td>91488.000000</td>\n",
       "      <td>119824.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>231.562278</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>39.003141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89900.000000</td>\n",
       "      <td>399550.000000</td>\n",
       "      <td>855909.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1168.233561</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>203.312149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BAD          LOAN        MORTDUE          VALUE   REASON  \\\n",
       "count   5960.000000   5960.000000    5442.000000    5848.000000     5708   \n",
       "unique          NaN           NaN            NaN            NaN        2   \n",
       "top             NaN           NaN            NaN            NaN  DebtCon   \n",
       "freq            NaN           NaN            NaN            NaN     3928   \n",
       "mean       0.199497  18607.969799   73760.817200  101776.048741      NaN   \n",
       "std        0.399656  11207.480417   44457.609458   57385.775334      NaN   \n",
       "min        0.000000   1100.000000    2063.000000    8000.000000      NaN   \n",
       "25%        0.000000  11100.000000   46276.000000   66075.500000      NaN   \n",
       "50%        0.000000  16300.000000   65019.000000   89235.500000      NaN   \n",
       "75%        0.000000  23300.000000   91488.000000  119824.250000      NaN   \n",
       "max        1.000000  89900.000000  399550.000000  855909.000000      NaN   \n",
       "\n",
       "          JOB          YOJ        DEROG       DELINQ        CLAGE  \\\n",
       "count    5681  5445.000000  5252.000000  5380.000000  5652.000000   \n",
       "unique      6          NaN          NaN          NaN          NaN   \n",
       "top     Other          NaN          NaN          NaN          NaN   \n",
       "freq     2388          NaN          NaN          NaN          NaN   \n",
       "mean      NaN     8.922268     0.254570     0.449442   179.766275   \n",
       "std       NaN     7.573982     0.846047     1.127266    85.810092   \n",
       "min       NaN     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       NaN     3.000000     0.000000     0.000000   115.116702   \n",
       "50%       NaN     7.000000     0.000000     0.000000   173.466667   \n",
       "75%       NaN    13.000000     0.000000     0.000000   231.562278   \n",
       "max       NaN    41.000000    10.000000    15.000000  1168.233561   \n",
       "\n",
       "               NINQ         CLNO      DEBTINC  \n",
       "count   5450.000000  5738.000000  4693.000000  \n",
       "unique          NaN          NaN          NaN  \n",
       "top             NaN          NaN          NaN  \n",
       "freq            NaN          NaN          NaN  \n",
       "mean       1.186055    21.296096    33.779915  \n",
       "std        1.728675    10.138933     8.601746  \n",
       "min        0.000000     0.000000     0.524499  \n",
       "25%        0.000000    15.000000    29.140031  \n",
       "50%        1.000000    20.000000    34.818262  \n",
       "75%        2.000000    26.000000    39.003141  \n",
       "max       17.000000    71.000000   203.312149  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()\n",
    "data.sample()\n",
    "data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns.tolist():\n",
    "    if data[col].dtype =='object':\n",
    "        data[col] = pd.Categorical(data[col])\n",
    "    else:\n",
    "        data[col] = data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BAD         float64\n",
       "LOAN        float64\n",
       "MORTDUE     float64\n",
       "VALUE       float64\n",
       "REASON     category\n",
       "JOB        category\n",
       "YOJ         float64\n",
       "DEROG       float64\n",
       "DELINQ      float64\n",
       "CLAGE       float64\n",
       "NINQ        float64\n",
       "CLNO        float64\n",
       "DEBTINC     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['BAD']\n",
    "X = data.drop(columns=['BAD'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to replace missing values in categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_values(df = data):\n",
    "  for col in data.columns.tolist():\n",
    "    if ('REASON' in col or 'JOB' in col):\n",
    "      data[col] = data[col].cat.add_categories('MISSING').fillna('MISSING')\n",
    "  return(data)    \n",
    "\n",
    "X = replace_missing_values(df = X)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4470, 13), (1490, 13), (4470,), (1490,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    #stratify = y,\n",
    "                                                    random_state=0)\n",
    "                                                    \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric features\n",
    "numeric_features = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# categorical features\n",
    "categorical_features = ['JOB', 'REASON']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# preprocessing num and cat data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logistic_regression = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                           ('logReg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.833\n"
     ]
    }
   ],
   "source": [
    "pipe_logistic_regression.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % pipe_logistic_regression.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid kernel shutdown\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "pipe_XGBoost = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('xgboost', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.898\n"
     ]
    }
   ],
   "source": [
    "pipe_XGBoost.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % pipe_XGBoost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_NN = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('nn', MLPClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris.schulz/anaconda3/envs/r-reticulate/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe_NN.fit(X_train, y_train)                               \n",
    "print(\"model score: %.3f\" % pipe_NN.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_lg = pipe_logistic_regression.predict_proba(X_test)[:,1].tolist()\n",
    "y_predicted_xg = pipe_XGBoost.predict_proba(X_test)[:,1].tolist()\n",
    "y_predicted_nn = pipe_NN.predict_proba(X_test)[:,1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    {\n",
    "        'legend_names' : 'LogReg',\n",
    "        'y_empirical': y_test.tolist(),\n",
    "        'y_predicted': y_predicted_lg,\n",
    "    },\n",
    "    {\n",
    "        'legend_names' : 'xgBoost',\n",
    "        'y_empirical': y_test.tolist(),\n",
    "        'y_predicted': y_predicted_xg,        \n",
    "    },\n",
    "    {\n",
    "        'legend_names' : 'NN',\n",
    "        'y_empirical': y_test.tolist(),\n",
    "        'y_predicted': y_predicted_nn,\n",
    "    }        \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model(models = model_list):\n",
    "    for m in models:\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(m['y_empirical'], m['y_predicted'])\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        plt.plot(false_positive_rate, true_positive_rate, label='%s ROC (area = %0.2f)' % (m['legend_names'], roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc=\"lower right\", fontsize='small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several subtasks regarding ROC are included in the case study. I skip over them for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": stream",
     "text": [
      "{'logReg': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False),\n",
      " 'logReg__C': 1.0,\n",
      " 'logReg__class_weight': None,\n",
      " 'logReg__dual': False,\n",
      " 'logReg__fit_intercept': True,\n",
      " 'logReg__intercept_scaling': 1,\n",
      " 'logReg__max_iter': 100,\n",
      " 'logReg__multi_class': 'warn',\n",
      " 'logReg__n_jobs': None,\n",
      " 'logReg__penalty': 'l2',\n",
      " 'logReg__random_state': None,\n",
      " 'logReg__solver': 'warn',\n",
      " 'logReg__tol': 0.0001,\n",
      " 'logReg__verbose': 0,\n",
      " 'logReg__warm_start': False,\n",
      " 'memory': None,\n",
      " 'preprocessor': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
      "         transformer_weights=None,\n",
      "         transformers=[('num', Pipeline(memory=None,\n",
      "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
      "       strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))]), ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLA...numpy.float64'>, handle_unknown='ignore',\n",
      "       n_values=None, sparse=True))]), ['JOB', 'REASON'])]),\n",
      " 'preprocessor__cat': Pipeline(memory=None,\n",
      "     steps=[('imputer', SimpleImputer(copy=True, fill_value='missing', missing_values=nan,\n",
      "       strategy='constant', verbose=0)), ('onehot', OneHotEncoder(categorical_features=None, categories=None,\n",
      "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
      "       n_values=None, sparse=True))]),\n",
      " 'preprocessor__cat__imputer': SimpleImputer(copy=True, fill_value='missing', missing_values=nan,\n",
      "       strategy='constant', verbose=0),\n",
      " 'preprocessor__cat__imputer__copy': True,\n",
      " 'preprocessor__cat__imputer__fill_value': 'missing',\n",
      " 'preprocessor__cat__imputer__missing_values': nan,\n",
      " 'preprocessor__cat__imputer__strategy': 'constant',\n",
      " 'preprocessor__cat__imputer__verbose': 0,\n",
      " 'preprocessor__cat__memory': None,\n",
      " 'preprocessor__cat__onehot': OneHotEncoder(categorical_features=None, categories=None,\n",
      "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
      "       n_values=None, sparse=True),\n",
      " 'preprocessor__cat__onehot__categorical_features': None,\n",
      " 'preprocessor__cat__onehot__categories': None,\n",
      " 'preprocessor__cat__onehot__dtype': <class 'numpy.float64'>,\n",
      " 'preprocessor__cat__onehot__handle_unknown': 'ignore',\n",
      " 'preprocessor__cat__onehot__n_values': None,\n",
      " 'preprocessor__cat__onehot__sparse': True,\n",
      " 'preprocessor__cat__steps': [('imputer',\n",
      "                               SimpleImputer(copy=True, fill_value='missing', missing_values=nan,\n",
      "       strategy='constant', verbose=0)),\n",
      "                              ('onehot',\n",
      "                               OneHotEncoder(categorical_features=None, categories=None,\n",
      "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
      "       n_values=None, sparse=True))],\n",
      " 'preprocessor__n_jobs': None,\n",
      " 'preprocessor__num': Pipeline(memory=None,\n",
      "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
      "       strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))]),\n",
      " 'preprocessor__num__imputer': SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
      "       strategy='median', verbose=0),\n",
      " 'preprocessor__num__imputer__copy': True,\n",
      " 'preprocessor__num__imputer__fill_value': None,\n",
      " 'preprocessor__num__imputer__missing_values': nan,\n",
      " 'preprocessor__num__imputer__strategy': 'median',\n",
      " 'preprocessor__num__imputer__verbose': 0,\n",
      " 'preprocessor__num__memory': None,\n",
      " 'preprocessor__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      " 'preprocessor__num__scaler__copy': True,\n",
      " 'preprocessor__num__scaler__with_mean': True,\n",
      " 'preprocessor__num__scaler__with_std': True,\n",
      " 'preprocessor__num__steps': [('imputer',\n",
      "                               SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
      "       strategy='median', verbose=0)),\n",
      "                              ('scaler',\n",
      "                               StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
      " 'preprocessor__remainder': 'drop',\n",
      " 'preprocessor__sparse_threshold': 0.3,\n",
      " 'preprocessor__transformer_weights': None,\n",
      " 'preprocessor__transformers': [('num',\n",
      "                                 Pipeline(memory=None,\n",
      "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
      "       strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))]),\n",
      "                                 ['LOAN',\n",
      "                                  'MORTDUE',\n",
      "                                  'VALUE',\n",
      "                                  'YOJ',\n",
      "                                  'DEROG',\n",
      "                                  'DELINQ',\n",
      "                                  'CLAGE',\n",
      "                                  'NINQ',\n",
      "                                  'CLNO',\n",
      "                                  'DEBTINC']),\n",
      "                                ('cat',\n",
      "                                 Pipeline(memory=None,\n",
      "     steps=[('imputer', SimpleImputer(copy=True, fill_value='missing', missing_values=nan,\n",
      "       strategy='constant', verbose=0)), ('onehot', OneHotEncoder(categorical_features=None, categories=None,\n",
      "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
      "       n_values=None, sparse=True))]),\n",
      "                                 ['JOB', 'REASON'])],\n",
      " 'steps': [('preprocessor',\n",
      "            ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
      "         transformer_weights=None,\n",
      "         transformers=[('num', Pipeline(memory=None,\n",
      "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
      "       strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))]), ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLA...numpy.float64'>, handle_unknown='ignore',\n",
      "       n_values=None, sparse=True))]), ['JOB', 'REASON'])])),\n",
      "           ('logReg',\n",
      "            LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))]}\n"
     ]
    }
   ],
   "source": [
    "# check hyperparameters\n",
    "pprint(pipe_logistic_regression.fit(X_train, y_train).get_params())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space and regularization hyperparameter space\n",
    "\n",
    "params={'logReg__C':[.01,.05,.1,.5,1,5,10],\n",
    "        'logReg__penalty':['l1','l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.05\n"
     ]
    }
   ],
   "source": [
    "# use hyperparameter grid from above in Cross Validation\n",
    "\n",
    "CV_logReg  = GridSearchCV(pipe_logistic_regression, param_grid=params, cv=5, verbose=0)\n",
    "\n",
    "# fit the model\n",
    "bestModel_logReg = CV_logReg.fit(X_train, y_train)\n",
    "\n",
    "print('Best Penalty:', bestModel_logReg.best_estimator_.get_params()['logReg__penalty'])\n",
    "print('Best C:', bestModel_logReg.best_estimator_.get_params()['logReg__C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logReg = bestModel_logReg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized Log Reg Score: 0.8393736017897092\n"
     ]
    }
   ],
   "source": [
    "print(\"optimized Log Reg Score:\", bestlogreg.score(X_train,y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check hyperparameters\n",
    "pprint(pipe_XGBoost.fit(X_train, y_train).get_params())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "\n",
    "params = {'xgboost__min_child_weight': [1, 5, 10],\n",
    "        'xgboost__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'xgboost__subsample': [0.6, 0.8, 1.0],\n",
    "        'xgboost__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'xgboost__max_depth': [3, 4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Min Child Weight: 1\n",
      "Best Gamma: 1\n",
      "Best Colsample Bytree: 0.8\n",
      "Best Max Depth: 5\n"
     ]
    }
   ],
   "source": [
    "# use hyperparameter grid from above in Cross Validation\n",
    "\n",
    "CV_Xgboost  = GridSearchCV(pipe_XGBoost, param_grid=params, cv=5, verbose=0)\n",
    "\n",
    "# fit the model\n",
    "bestModel_Xgboost = CV_Xgboost.fit(X_train, y_train)\n",
    "\n",
    "print('Best Min Child Weight:', bestModel_Xgboost.best_estimator_.get_params()['xgboost__min_child_weight'])\n",
    "print('Best Gamma:', bestModel_Xgboost.best_estimator_.get_params()['xgboost__gamma'])\n",
    "print('Best Colsample Bytree:', bestModel_Xgboost.best_estimator_.get_params()['xgboost__colsample_bytree'])\n",
    "print('Best Max Depth:', bestModel_Xgboost.best_estimator_.get_params()['xgboost__max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized XgBoost Score: 0.9568232662192394\n"
     ]
    }
   ],
   "source": [
    "best_Xgboost = bestModel_Xgboost.best_estimator_\n",
    "print(\"optimized XgBoost Score:\", best_Xgboost.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
